{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQ2gIGIk53CQkZh/OWxQp/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 토큰화 숙제 1\n","### 활용 데이터: hw_sample.json\n","\n","### 실습 개요\n","이 실습에서는 주어진 json 파일에 포함된 텍스트 데이터에 대해 Mecab 형태소 분석기를 사용하여 형태소 분석을 수행하고, 그 결과를 기존 데이터 프레임에 새로운 열로 추가하는 과제입니다. KoNLPy 라이브러리 Mecab 형태소 분석기를 활용하여 한국어 텍스트 데이터를 형태소 단위로 분리하고, 분리된 형태소를 각 행에 대응하는 새로운 열에 저장합니다.\n","\n","\n","### 실습 절차\n","1. 라이브러리 설치 및 임포트: 필요한 라이브러리 (pandas, konlpy)를 설치하고 임포트합니다.\n","2. json 파일 로드: pandas를 사용하여 주어진 json 파일을 읽고 분석하려는 DataFrame으로 변환합니다. (이때, paragraph키 값 내의 첫번째 sentences안의 텍스트들을 분석합니다.)\n","3. Mecab 인스턴스 생성: KoNLPy의 Mecab 클래스를 인스턴스화합니다.\n","4. 형태소 분석 수행: \"src_sentence\"열에 대해 apply함수를 사용하여 형태소 분석기로 형태소 분석을 수행합니다. (morphs 함수 활용)\n","5. 각 행의 텍스트 데이터에 대한 형태소 분석 결과를 새로운 (Mecab)에 저장합니다.\n","6. 결과 확인 및 저장: 형태소 분석 결과가 추가된 DataFrame을 확인한 다음 morphs_results.csv파일로 저장합니다.\n","\n"],"metadata":{"id":"JYLH5juiEVG5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuEuGcyIEM9A"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## 토큰화 숙제 2\n","### 활용 데이터: hw_sample.json\n","\n","### 실습 개요\n","이 실습에서는 hw_sample.json 데이터 셋을 활용하여 [klue/roberta-small](https://huggingface.co/klue/roberta-small)를 활용하여 토크나이징을 수행하고 그 결과를 기존 데이터 프레임에 새로운 열로 추가하는 과제입니다.\n","\n","### 실습 절차\n","1. 라이브러리 설치 및 임포트: 필요한 라이브러리 (transformers)를 설치하고 임포트 합니다.\n","2. json 파일 로드: pandas를 사용하여 주어진 json 파일을 읽고 분석하려는 DataFrame으로 변환합니다. (이때, paragraph키 값 내의 두번째 sentences안의 텍스트들을 분석합니다.)\n","3. 모델 로드: transformers를 활용해 모델을 읽습니다.\n","4. 토크나이징: src_sentence에 대해 토크나이징을 수행합니다.\n","5. 토크나이징한 결과를 새로운 칼럼(tokenize_rst)에 저장합니다.\n","6. 결과 확인 및 저장: DataFrame을 확인한 다음 tokenize_results.csv파일로 저장합니다.\n","\n"],"metadata":{"id":"Vp5P3WwQH5u1"}},{"cell_type":"code","source":[],"metadata":{"id":"UlJUczxLJK3c"},"execution_count":null,"outputs":[]}]}