{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4v4xHPz8dPJhLrI87g7Fg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 임베딩 실습\n","### 활용 데이터: sample.csv\n","\n","### 실습 개요\n","이 실습에서는 sample.csv 파일에 포함된 두 개의 텍스트 칼럼에 대해 Sentence-BERT를 활용하여 임베딩 값을 추출하고, 추출된 두 임베딩 간의 코사인 유사도를 계산하는 과제를 수행합니다. Sentence-BERT 라이브러리를 사용하여 텍스트 데이터를 고차원 벡터로 변환하고, 이 벡터들 사이의 유사도를 측정하는 방법을 실습합니다.\n","\n","\n","### 실습 절차\n","1. 라이브러리 설치 및 임포트: 필요한 라이브러리 (pandas, sentence_transformers)를 설치하고 임포트합니다.\n","2. CSV 파일 로드: pandas를 사용하여 주어진 CSV 파일을 읽고 DataFrame으로 변환합니다.\n","3. Sentence-BERT 모델 로드: sentence_transformers의 SentenceTransformer 클래스를 사용하여 사전 훈련된 모델을 로드합니다.\n","4. 텍스트 데이터 임베딩: DataFrame 내의 두 텍스트 칼럼에 대해 각각 임베딩을 계산합니다.\n","5. 코사인 유사도 계산: 추출된 두 임베딩 벡터 간의 코사인 유사도를 계산합니다.\n","6. 결과 확인 및 저장: 계산된 코사인 유사도를 새로운 열에 저장하고, 최종 결과를 cosine_similarity_results.csv 파일로 저장합니다.태소 분석 결과가 추가된 DataFrame을 확인한 다음 morphs_results.csv파일로 저장합니다."],"metadata":{"id":"0L7WeKefEIvh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUXHDxkWBwjf"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## BLEU 및 SacreBLEU 점수 계산 실습\n","\n","### 활용 데이터: sample.csv\n","\n","### 실습 개요\n","이 실습에서는 주어진 csv 파일에 포함된 두 칼럼의 텍스트 데이터를 사용하여 BLEU(Bilingual Evaluation Understudy) 점수와 SacreBLEU 점수를 계산하는 과제를 수행합니다.\n","\n","\n","### 실습 절차\n","1. 라이브러리 설치 및 임포트: 필요한 라이브러리 (pandas, nltk, sacrebleu)를 설치하고 임포트합니다.\n","2. CSV 파일 로드: pandas를 사용하여 주어진 CSV 파일을 읽고 DataFrame으로 변환합니다.\n","3. BLEU 점수 계산: nltk 라이브러리의 sentence_bleu 함수를 사용하여 BLEU 점수를 계산합니다. (이때, ngram-1,2,3에 대해 각각 따로 계산합니다.)\n","4. SacreBLEU 점수 계산: sacrebleu 라이브러리를 사용하여 SacreBLEU 점수를 계산합니다.\n","5. 결과 저장 및 비교: 두 방법으로 계산된 BLEU 점수를 각각 새로운 열에 저장하고, 결과를 비교 분석합니다.\n","6. 최종 결과 저장: 계산된 BLEU 및 SacreBLEU 점수가 포함된 DataFrame을 bleu_sacrebleu_results.csv 파일로 저장합니다."],"metadata":{"id":"9sNyzvnpdXN9"}},{"cell_type":"code","source":[],"metadata":{"id":"N8onw6wzd-oM"},"execution_count":null,"outputs":[]}]}