{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKyUQgIqGWAl/RHUAr/ngC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 데이터 정제\n","\n","### 활용 데이터: sample.json\n","\n","### 실습 개요\n","이 실습에서는 Google Colab에 json 파일을 마운트 하고, Json데이터를 Pandas 라이브러리를 사용하여 데이터 프레임으로 변환한 다음, 전처리를 진행한 후 특정 컬럼의 데이터를 분석합니다. 구체적으로, 이메일 주소와 특수기호가 텍스트에 포함되어있을 경우 이를 제거한 다음, 'en'과 'ko' 라는 두 개의 컬럼에 대해 각각 띄어쓰기로 분할하여 단어의 수를 세고, 이 정보를 새로운 컬럼에 저장합니다.\n","  \n","  \n","### 실습 절차\n","1. CSV 파일 마운트: Google Colab에 json 파일을 업로드합니다.\n","2. 데이터 읽기: Pandas를 사용하여 json파일을 DataFrame으로 변환합니다.\n","3. 데이터 처리:\n","- 'en'과 'ko' 컬럼의 데이터에 이메일 주소와 특수기호가 포함되어있을 경우 제거합니다.\n","- 'en'과 'ko' 컬럼의 데이터를 띄어쓰기 단위로 분할합니다.\n","- 각 행에 대해 영어와 한국어 단어의 개수를 세고, 이를 새로운 컬럼에 저장합니다.\n","4. en 칼럼에 대해 길이가 긴 순서대로 DataFrame을 재 정렬합니다."],"metadata":{"id":"WnL3FvGU7Pck"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yASaSNvcGVg"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["## 데이터 토큰화\n","\n","### 실습 개요\n","\n","앞서 실습한 데이터 정제된 데이터 셋에 대해 Hannanum 형태소 분석기를 사용하여 형태소 분석을 수행하고, 그 결과를 기존 데이터 프레임에 새로운 열로 추가하는 과제입니다. KoNLPy 라이브러리의 Hannanum 형태소 분석기를 활용하여 한국어 텍스트 데이터를 형태소 단위로 분리하고, 분리된 형태소를 각 행에 대응하는 새로운 열에 저장합니다.  \n","  \n","  \n","### 실습 절차\n","\n","1. 라이브러리 설치 및 임포트: 필요한 라이브러리 (pandas, konlpy)를 설치하고 임포트합니다.\n","2. CSV 파일 로드: pandas를 사용하여 주어진 CSV 파일을 읽고 DataFrame으로 변환합니다.\n","3. Hannanum 인스턴스 생성: KoNLPy의 Hannanum 클래스를 인스턴스화합니다.\n","4. 형태소 분석 수행: CSV 파일의 특정 열(예: 텍스트 데이터가 포함된 열)에 대해 반복문을 사용하여 Okt 형태소 분석기로 형태소 분석을 수행합니다.\n","5. 각 행의 텍스트 데이터에 대한 형태소 분석 결과를 새로운 열에 저장합니다.\n","6. 결과 확인 및 저장: 형태소 분석 결과가 추가된 DataFrame을 확인합니다."],"metadata":{"id":"ALLnA2wW7bfr"}},{"cell_type":"code","source":[],"metadata":{"id":"LAIJdZhG7fvF"},"execution_count":null,"outputs":[]}]}